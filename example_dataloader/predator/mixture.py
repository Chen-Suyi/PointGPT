"""
Author: Shengyu Huang
Last modified: 30.11.2020
"""

import os,sys,glob,torch
import numpy as np
from scipy.spatial.transform import Rotation
from torch.utils.data import Dataset
import open3d as o3d
from lib.benchmark_utils import to_o3d_pcd, to_tsfm, get_correspondences
from lib.utils import load_obj


def uniform_sample_rotation() -> np.ndarray:
    """Random rotation matrix generated from QR decomposition

    Rotation generated by this function is uniformly distributed on SO(3) w.r.t Haar measure

    NOTE: RRE of the rotation generated by this function is NOT uniformly distributed
    
    """
    # QR decomposition
    z = np.random.randn(3, 3)
    while np.linalg.matrix_rank(z) != z.shape[0]:
        z = np.random.randn(3, 3)
    q, r = np.linalg.qr(z)
    d = np.diag(r)
    ph = np.diag(d / np.absolute(d))
    q = np.matmul(q, ph)
    rotation = q / np.linalg.det(q)

    return rotation


def gaussian_sample_translation(translation_factor: float = 1.0) -> np.ndarray:
    """Random translation uniformly distributed in sphere
    """
    # gaussian
    translation = np.random.randn(3) * translation_factor
    return translation

class MixtureDataset(Dataset):
    """
    Load subsampled coordinates, relative rotation and translation
    Output(torch.Tensor):
        src_pcd:        [N,3]
        tgt_pcd:        [M,3]
        rot:            [3,3]
        trans:          [3,1]
    """
    def __init__(self, infos, config, extra_root, data_augmentation=True):
        super(MixtureDataset,self).__init__()
        self.infos = infos
        self.base_dir = config.root
        self.extra_root = extra_root # set extra_root to the path to generated data
        self.overlap_radius = config.overlap_radius
        self.data_augmentation=data_augmentation
        self.config = config
        
        self.rot_factor=1.
        self.augment_noise = config.augment_noise
        self.max_points = 30000

        for idx, info in enumerate(self.infos['src']):
            self.infos['src'][idx] = os.path.join(self.base_dir,info)
        for idx, info in enumerate(self.infos['tgt']):
            self.infos['tgt'][idx] = os.path.join(self.base_dir,info)

        # loading generated data
        self.metadata_dir = os.path.join(self.extra_root, "metadata", "gt.log")
        with open(self.metadata_dir, "r") as f:
            for line in f.readlines():
                scene_name, src_idx, tgt_idx, src_overlap, tgt_overlap = line.split("\t")
                src_path = os.path.join(self.extra_root, "data", scene_name, "sample-{:0>6d}.cloud.ply".format(int(src_idx)))
                tgt_path = os.path.join(self.extra_root, "data", scene_name, "sample-{:0>6d}.cloud.ply".format(int(tgt_idx)))
                self.infos['src'].append(src_path)
                self.infos['tgt'].append(tgt_path)

    def __len__(self):
        return len(self.infos['tgt'])
    
    def _load_point_cloud(self, file_path):
        if file_path.endswith('.ply'):
            pcd = o3d.io.read_point_cloud(file_path)
            points = np.asarray(pcd.points)
        elif file_path.endswith('.bin'):
            points = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)
        elif file_path.endswith('.pth'):
            points = torch.load(file_path)
            if not isinstance(points, np.ndarray):
                points = points.numpy()
        else:
            raise AssertionError('Cannot recognize point cloud format')

        return points
    

    def __getitem__(self,item): 
        # get pointcloud
        src_path=self.infos['src'][item]
        tgt_path=self.infos['tgt'][item]
        src_pcd = self._load_point_cloud(src_path)
        tgt_pcd = self._load_point_cloud(tgt_path)

        # get transformation
        if item < len(self.infos['rot']):
            rot=self.infos['rot'][item]
            trans=self.infos['trans'][item]
        else:
            rot=uniform_sample_rotation()
            trans=gaussian_sample_translation()
            # apply transform
            src_pcd = (src_pcd - trans) @ rot

        # if we get too many points, we do some downsampling
        if(src_pcd.shape[0] > self.max_points):
            idx = np.random.permutation(src_pcd.shape[0])[:self.max_points]
            src_pcd = src_pcd[idx]
        if(tgt_pcd.shape[0] > self.max_points):
            idx = np.random.permutation(tgt_pcd.shape[0])[:self.max_points]
            tgt_pcd = tgt_pcd[idx]

        # add gaussian noise
        if self.data_augmentation:            
            # rotate the point cloud
            euler_ab=np.random.rand(3)*np.pi*2/self.rot_factor # anglez, angley, anglex
            rot_ab= Rotation.from_euler('zyx', euler_ab).as_matrix()
            if(np.random.rand(1)[0]>0.5):
                src_pcd=np.matmul(rot_ab,src_pcd.T).T
                rot=np.matmul(rot,rot_ab.T)
            else:
                tgt_pcd=np.matmul(rot_ab,tgt_pcd.T).T
                rot=np.matmul(rot_ab,rot)
                trans=np.matmul(rot_ab,trans)

            src_pcd += (np.random.rand(src_pcd.shape[0],3) - 0.5) * self.augment_noise
            tgt_pcd += (np.random.rand(tgt_pcd.shape[0],3) - 0.5) * self.augment_noise
        
        if(trans.ndim==1):
            trans=trans[:,None]

        # get correspondence at fine level
        tsfm = to_tsfm(rot, trans)
        correspondences = get_correspondences(to_o3d_pcd(src_pcd), to_o3d_pcd(tgt_pcd), tsfm,self.overlap_radius)
            
        src_feats=np.ones_like(src_pcd[:,:1]).astype(np.float32)
        tgt_feats=np.ones_like(tgt_pcd[:,:1]).astype(np.float32)
        rot = rot.astype(np.float32)
        trans = trans.astype(np.float32)
        
        return src_pcd,tgt_pcd,src_feats,tgt_feats,rot,trans, correspondences, src_pcd, tgt_pcd, torch.ones(1)